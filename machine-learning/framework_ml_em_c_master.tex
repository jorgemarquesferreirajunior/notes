\documentclass[12pt]{book}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{geometry}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{color}
\usepackage{tikz}
\usetikzlibrary{positioning, shapes, arrows, calc}

\geometry{margin=1in, paperwidth=7in, paperheight=10in}
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{cstyle}{
    language=C,
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2,
    frame=single
}

\lstset{style=cstyle}

\newtheorem{definition}{Definição}[chapter]
\newtheorem{theorem}{Teorema}[chapter]
\newtheorem{lemma}{Lema}[chapter]
\newtheorem{corollary}{Corolário}[chapter]
\newtheorem{example}{Exemplo}[chapter]

\title{Construindo um Framework Completo de Deep Learning em C \\
\large Do Zero ao Produção: Matemática, Algoritmos e Arquitetura}
\author{Guia Master Avançado}
\date{\today}

\begin{document}

\maketitle
\tableofcontents
\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{Prefácio}
Este livro não é apenas um tutorial superficial. É uma jornada profunda através de todos os aspectos do deep learning, desde os fundamentos matemáticos mais abstratos até os detalhes de implementação de baixo nível em C puro.

A cada capítulo, você não apenas aprenderá conceitos, mas implementará código funcional e testado. Ao final, você terá construído um framework completo equivalente a um PyTorch simplificado, totalmente funcional e capaz de treinar redes neurais complexas.

\vspace{1cm}
\noindent
\textbf{Pré-requisitos:}
\begin{itemize}
    \item Conhecimento sólido de C (ponteiros, alocação dinâmica, structs)
    \item Matemática básica de graduação (cálculo, álgebra linear)
    \item Vontade de entender cada detalhe
\end{itemize}

\vspace{1cm}
\noindent
\textbf{Quanto tempo leva?} \\
Implementar todo o framework do zero pode levar de 2 a 3 meses de trabalho dedicado. Cada capítulo contém exercícios que consolidam o aprendizado.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Fundamentos Matemáticos e Teóricos do Aprendizado}

\section{O Problema Fundamental do Aprendizado}

O aprendizado de máquina supervisionado pode ser formalizado como um problema de otimização. Dado um conjunto de dados $\mathcal{D} = \{(\mathbf{x}_i, y_i)\}_{i=1}^N$ onde $\mathbf{x}_i \in \mathbb{R}^d$ e $y_i \in \mathbb{R}^k$, queremos encontrar uma função $f: \mathbb{R}^d \to \mathbb{R}^k$ parametrizada por $\theta$ que minimize:

\[
\theta^* = \arg \min_{\theta} \mathbb{E}_{(\mathbf{x},y) \sim p_{\text{data}}} [\mathcal{L}(f(\mathbf{x};\theta), y)]
\]

Na prática, como $p_{\text{data}}$ é desconhecida, aproximamos pelo risco empírico:

\[
\theta^* \approx \arg \min_{\theta} \frac{1}{N} \sum_{i=1}^N \mathcal{L}(f(\mathbf{x}_i;\theta), y_i)
\]

\subsection{Espaço de Hipóteses e Capacidade}

Uma rede neural define um espaço de hipóteses $\mathcal{H}$. O teorema da aproximação universal (Cybenko, 1989) estabelece que uma rede feedforward com uma camada oculta pode aproximar qualquer função contínua em um compacto de $\mathbb{R}^d$.

\begin{theorem}[Aproximação Universal]
Seja $\sigma$ uma função de ativação não constante, limitada e monótona. Então o conjunto de funções da forma:
\[
f(\mathbf{x}) = \sum_{j=1}^m v_j \sigma(\mathbf{w}_j^T\mathbf{x} + b_j)
\]
é denso em $C([0,1]^d)$ no espaço das funções contínuas.
\end{theorem}

\section{Derivação Detalhada da Função de Custo}

\subsection{Mean Squared Error (MSE)}

Para problemas de regressão, assumimos que a variável alvo é gerada por:
\[
y = f(\mathbf{x};\theta) + \epsilon, \quad \epsilon \sim \mathcal{N}(0, \sigma^2)
\]

A verossimilhança dos dados é:
\[
p(y|\mathbf{x},\theta) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(y - f(\mathbf{x};\theta))^2}{2\sigma^2}\right)
\]

Tomando o log negativo:
\[
-\log p(y|\mathbf{x},\theta) = \frac{1}{2}\log(2\pi\sigma^2) + \frac{(y - f(\mathbf{x};\theta))^2}{2\sigma^2}
\]

Ignorando constantes, minimizar MSE é equivalente a maximizar a verossimilhança sob ruído Gaussiano.

\subsection{Cross-Entropy para Classificação}

Para classificação binária, assumimos $y \in \{0,1\}$ e modelamos:
\[
p(y=1|\mathbf{x}) = \sigma(f(\mathbf{x};\theta)) = \frac{1}{1+e^{-f(\mathbf{x};\theta)}}
\]

A verossimilhança:
\[
p(y|\mathbf{x}) = \sigma(f)^y (1-\sigma(f))^{1-y}
\]

Log-verossimilhança negativa:
\[
\mathcal{L} = -y\log(\sigma(f)) - (1-y)\log(1-\sigma(f))
\]

Para classificação multiclasse com $K$ classes, generalizamos via softmax:
\[
p(y=c|\mathbf{x}) = \frac{e^{f_c(\mathbf{x})}}{\sum_{j=1}^K e^{f_j(\mathbf{x})}}
\]
\[
\mathcal{L} = -\sum_{c=1}^K y_c \log p(y=c|\mathbf{x})
\]

\section{Otimização e Gradiente Descendente}

\subsection{Derivação do Gradiente}

Queremos minimizar $J(\theta) = \frac{1}{N}\sum_{i=1}^N \mathcal{L}(f(\mathbf{x}_i;\theta), y_i)$. A expansão em série de Taylor de primeira ordem:

\[
J(\theta + \Delta\theta) \approx J(\theta) + \nabla_\theta J(\theta)^T \Delta\theta
\]

Para garantir decréscimo, escolhemos $\Delta\theta = -\eta \nabla_\theta J(\theta)$:

\[
J(\theta + \Delta\theta) \approx J(\theta) - \eta \|\nabla_\theta J(\theta)\|^2 \leq J(\theta)
\]

\subsection{Análise de Convergência}

Sob hipóteses de suavidade de Lipschitz do gradiente:
\[
\|\nabla J(\theta_1) - \nabla J(\theta_2)\| \leq L \|\theta_1 - \theta_2\|
\]

Podemos provar que com $\eta \leq 1/L$:
\[
J(\theta_{t+1}) \leq J(\theta_t) - \frac{\eta}{2}\|\nabla J(\theta_t)\|^2
\]

\section{Regra da Cadeia Vetorial e Jacobianos}

O backpropagation é uma aplicação eficiente da regra da cadeia para funções compostas vetoriais. Seja $f: \mathbb{R}^m \to \mathbb{R}^n$ e $g: \mathbb{R}^n \to \mathbb{R}^p$. Então:
\[
\frac{\partial (g \circ f)}{\partial \mathbf{x}} = \frac{\partial g}{\partial \mathbf{f}} \cdot \frac{\partial \mathbf{f}}{\partial \mathbf{x}}
\]

Onde $\frac{\partial g}{\partial \mathbf{f}} \in \mathbb{R}^{p \times n}$ e $\frac{\partial \mathbf{f}}{\partial \mathbf{x}} \in \mathbb{R}^{n \times m}$.

\subsection{Diferença entre Gradiente e Jacobiano}

Para uma função escalar $L: \mathbb{R}^n \to \mathbb{R}$, $\nabla L$ é um vetor. Para uma função vetorial $\mathbf{f}: \mathbb{R}^n \to \mathbb{R}^m$, a derivada é uma matriz Jacobiana.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Implementação Base em C: Estruturas e Gerenciamento de Memória}

\section{Gerenciamento de Memória para Tensores}

A base de qualquer framework é o gerenciamento eficiente de arrays multidimensionais. Vamos implementar do zero:

\begin{lstlisting}[language=C, caption=Estrutura base do Tensor]
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <math.h>
#include <assert.h>

typedef struct Tensor {
    float* data;          // Dados contíguos em memória
    float* grad;          // Gradientes acumulados
    int* shape;           // Dimensões do tensor (ex: [3,224,224])
    int ndim;             // Número de dimensões
    int size;             // Produto das dimensões
    int refcount;         // Contagem de referências para garbage collection
    
    // Para autograd (será expandido depois)
    struct Tensor* grad_fn;
    void (*backward)(struct Tensor*);
    
    char requires_grad;   // Se calcula gradientes
} Tensor;
\end{lstlisting}

\section{Funções de Criação e Destruição}

\begin{lstlisting}[language=C, caption=Alocação e liberação de memória]
Tensor* tensor_create(int* shape, int ndim) {
    Tensor* t = (Tensor*)malloc(sizeof(Tensor));
    t->ndim = ndim;
    t->shape = (int*)malloc(ndim * sizeof(int));
    
    t->size = 1;
    for(int i = 0; i < ndim; i++) {
        t->shape[i] = shape[i];
        t->size *= shape[i];
    }
    
    t->data = (float*)calloc(t->size, sizeof(float));
    t->grad = (float*)calloc(t->size, sizeof(float));
    t->refcount = 1;
    t->requires_grad = 1;
    t->grad_fn = NULL;
    
    return t;
}

void tensor_free(Tensor* t) {
    if(!t) return;
    
    t->refcount--;
    if(t->refcount > 0) return;
    
    free(t->data);
    free(t->grad);
    free(t->shape);
    free(t);
}
\end{lstlisting}

\section{Operações Básicas Otimizadas}

Operações vetorizadas usando loops otimizados:

\begin{lstlisting}[language=C, caption=Operações element-wise]
void tensor_add_scalar(Tensor* t, float scalar) {
    for(int i = 0; i < t->size; i++) {
        t->data[i] += scalar;
    }
}

void tensor_multiply_elementwise(Tensor* a, Tensor* b, Tensor* out) {
    assert(a->size == b->size && a->size == out->size);
    
    for(int i = 0; i < a->size; i++) {
        out->data[i] = a->data[i] * b->data[i];
    }
    
    if(a->requires_grad || b->requires_grad) {
        // Guardar para backpropagation
        out->requires_grad = 1;
    }
}
\end{lstlisting}

\section{Produto Matricial Otimizado}

Implementação de multiplicação de matrizes com três loops aninhados (O(n³)) - posteriormente otimizaremos com blocagem e SIMD:

\begin{lstlisting}[language=C, caption=Multiplicação de matrizes]
void tensor_matmul(Tensor* a, Tensor* b, Tensor* out) {
    // Assume a: [m, k], b: [k, n], out: [m, n]
    int m = a->shape[0];
    int k = a->shape[1];
    int n = b->shape[1];
    
    assert(a->shape[1] == b->shape[0]);
    
    for(int i = 0; i < m; i++) {
        for(int j = 0; j < n; j++) {
            float sum = 0.0f;
            for(int l = 0; l < k; l++) {
                sum += a->data[i * k + l] * b->data[l * n + j];
            }
            out->data[i * n + j] = sum;
        }
    }
}
\end{lstlisting}

\section{Estratégias de Otimização de Memória}

\subsection{Pooling de Alocação}
Para evitar fragmentação de memória, implementamos um pool de alocação:

\begin{lstlisting}[language=C, caption=Alocador de memória customizado]
typedef struct MemoryPool {
    void* memory;
    size_t size;
    size_t used;
} MemoryPool;

MemoryPool* pool_create(size_t size) {
    MemoryPool* pool = malloc(sizeof(MemoryPool));
    pool->memory = malloc(size);
    pool->size = size;
    pool->used = 0;
    return pool;
}

void* pool_alloc(MemoryPool* pool, size_t size) {
    if(pool->used + size > pool->size) return NULL;
    void* ptr = pool->memory + pool->used;
    pool->used += size;
    return ptr;
}
\end{lstlisting}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Rede Neural: Matemática e Implementação Detalhada}

\section{Arquitetura de uma Rede Neural}

\subsection{Neurônio Artificial: Modelo Matemático}

Um neurônio artificial implementa:
\[
z = \mathbf{w}^T\mathbf{x} + b = \sum_{i=1}^n w_i x_i + b
\]
\[
a = \phi(z)
\]

Onde $\phi$ é a função de ativação. As derivadas são cruciais para backpropagation:

\begin{itemize}
    \item Sigmoid: $\sigma(z) = \frac{1}{1+e^{-z}}$, $\sigma'(z) = \sigma(z)(1-\sigma(z))$
    \item Tanh: $\tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}$, $\tanh'(z) = 1 - \tanh^2(z)$
    \item ReLU: $\text{ReLU}(z) = \max(0,z)$, $\text{ReLU}'(z) = \begin{cases} 1 & z > 0 \\ 0 & z \leq 0 \end{cases}$
\end{itemize}

\section{Backpropagation: Derivação Passo a Passo}

\subsection{Caso Simples: 2 Camadas}

Considere uma rede com uma camada oculta:
\begin{align*}
z_1 &= W_1 x + b_1 \\
a_1 &= \sigma(z_1) \\
z_2 &= W_2 a_1 + b_2 \\
\hat{y} &= z_2 \quad \text{(regressão)}
\end{align*}

Função de custo MSE:
\[
L = \frac{1}{2}(\hat{y} - y)^2
\]

\subsubsection{Derivadas da Camada de Saída}
\[
\frac{\partial L}{\partial \hat{y}} = \hat{y} - y
\]
\[
\frac{\partial L}{\partial W_2} = \frac{\partial L}{\partial \hat{y}} \cdot \frac{\partial \hat{y}}{\partial z_2} \cdot \frac{\partial z_2}{\partial W_2} = (\hat{y} - y) \cdot 1 \cdot a_1^T
\]
\[
\frac{\partial L}{\partial b_2} = (\hat{y} - y) \cdot 1 \cdot 1
\]

\subsubsection{Derivadas da Camada Oculta}
\[
\frac{\partial L}{\partial a_1} = \frac{\partial L}{\partial \hat{y}} \cdot \frac{\partial \hat{y}}{\partial z_2} \cdot \frac{\partial z_2}{\partial a_1} = (\hat{y} - y) \cdot 1 \cdot W_2^T
\]
\[
\frac{\partial L}{\partial z_1} = \frac{\partial L}{\partial a_1} \cdot \frac{\partial a_1}{\partial z_1} = \frac{\partial L}{\partial a_1} \odot \sigma'(z_1)
\]
\[
\frac{\partial L}{\partial W_1} = \frac{\partial L}{\partial z_1} \cdot \frac{\partial z_1}{\partial W_1} = \frac{\partial L}{\partial z_1} \cdot x^T
\]
\[
\frac{\partial L}{\partial b_1} = \frac{\partial L}{\partial z_1}
\]

\subsection{Implementação Completa do Backprop}

\begin{lstlisting}[language=C, caption=Backpropagation para MLP de 2 camadas]
typedef struct Layer {
    Tensor* weights;
    Tensor* bias;
    Tensor* input;
    Tensor* output;
    Tensor* z;  // Pré-ativação
    char activation; // 's' sigmoid, 'r' relu, 't' tanh, 'n' none
} Layer;

typedef struct MLP {
    Layer** layers;
    int n_layers;
    Tensor* (*forward)(struct MLP*, Tensor*);
    void (*backward)(struct MLP*, Tensor* loss);
} MLP;

void mlp_backward(MLP* net, Tensor* loss_grad) {
    Tensor* grad = loss_grad; // dL/dy
    
    for(int l = net->n_layers - 1; l >= 0; l--) {
        Layer* layer = net->layers[l];
        
        // Gradiente dos parâmetros da camada atual
        if(layer->weights->requires_grad) {
            // dL/dW = input^T * grad
            tensor_matmul_transpose(layer->input, grad, 
                                   layer->weights->grad);
        }
        
        if(layer->bias->requires_grad) {
            // dL/db = sum(grad, axis=0)
            tensor_sum_axis(grad, 0, layer->bias->grad);
        }
        
        // Propagar gradiente para camada anterior
        if(l > 0) {
            // dL/d(input) = grad * W^T
            Tensor* new_grad = tensor_create(...);
            tensor_matmul(grad, layer->weights, new_grad, 1); // Transpose W
            
            // Multiplicar pela derivada da ativação
            if(layer->activation == 's') {
                tensor_sigmoid_prime(layer->z, layer->z_prime);
                tensor_multiply_elementwise(new_grad, layer->z_prime, new_grad);
            }
            // ... outras ativações
            
            grad = new_grad;
        }
    }
}
\end{lstlisting}

\section{Inicialização de Pesos}

A inicialização correta dos pesos é crítica para evitar gradientes desvanecentes/explosivos.

\subsection{Xavier/Glorot Initialization}
Para ativações sigmoid/tanh:
\[
W \sim \mathcal{U}\left(-\sqrt{\frac{6}{n_{\text{in}} + n_{\text{out}}}}, \sqrt{\frac{6}{n_{\text{in}} + n_{\text{out}}}}\right)
\]

\subsection{He Initialization}
Para ReLU:
\[
W \sim \mathcal{N}\left(0, \sqrt{\frac{2}{n_{\text{in}}}}\right)
\]

\begin{lstlisting}[language=C, caption=Inicializadores de peso]
void init_weights_xavier(Tensor* w, int fan_in, int fan_out) {
    float limit = sqrtf(6.0f / (fan_in + fan_out));
    for(int i = 0; i < w->size; i++) {
        w->data[i] = ((float)rand() / RAND_MAX) * 2 * limit - limit;
    }
}

void init_weights_he(Tensor* w, int fan_in) {
    float std = sqrtf(2.0f / fan_in);
    for(int i = 0; i < w->size; i++) {
        // Box-Muller transform
        float u1 = (float)rand() / RAND_MAX;
        float u2 = (float)rand() / RAND_MAX;
        w->data[i] = sqrtf(-2.0f * logf(u1)) * cosf(2 * M_PI * u2) * std;
    }
}
\end{lstlisting}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Sistema de Autograd Completo}

\section{Arquitetura do Grafo Computacional}

O autograd constrói um grafo acíclico dirigido (DAG) das operações.

\begin{lstlisting}[language=C, caption=Estrutura do nó do grafo]
typedef struct AutogradNode {
    Tensor* output;
    struct AutogradNode** parents;
    int n_parents;
    
    // Função que calcula gradientes dos pais
    void (*backward)(struct AutogradNode*);
    
    // Metadados da operação
    int op_type;  // 0: add, 1: mul, 2: matmul, 3: relu, ...
    void* op_ctx; // Contexto específico da operação
} AutogradNode;

typedef struct Tensor {
    // ... campos anteriores ...
    
    AutogradNode* grad_node;
    char grad_computed;  // Para evitar computação duplicada
} Tensor;
\end{lstlisting}

\section{Implementação de Operações com Grafo}

\begin{lstlisting}[language=C, caption=Operação de multiplicação com autograd]
Tensor* tensor_mul(Tensor* a, Tensor* b) {
    Tensor* out = tensor_create_like(a);  // Assume broadcasting implementado
    
    // Forward
    for(int i = 0; i < out->size; i++) {
        out->data[i] = a->data[i] * b->data[i];
    }
    
    // Setup autograd
    if(a->requires_grad || b->requires_grad) {
        out->requires_grad = 1;
        out->grad_node = (AutogradNode*)malloc(sizeof(AutogradNode));
        out->grad_node->output = out;
        out->grad_node->parents = (AutogradNode**)malloc(2 * sizeof(AutogradNode*));
        out->grad_node->parents[0] = a->grad_node;
        out->grad_node->parents[1] = b->grad_node;
        out->grad_node->n_parents = 2;
        out->grad_node->op_type = 1;  // multiplication
        out->grad_node->backward = mul_backward;
    }
    
    return out;
}

void mul_backward(AutogradNode* node) {
    Tensor* out = node->output;
    Tensor* a = node->parents[0]->output;
    Tensor* b = node->parents[1]->output;
    
    // dL/da = dL/dout * b
    if(a->requires_grad) {
        for(int i = 0; i < a->size; i++) {
            a->grad[i] += out->grad[i] * b->data[i];
        }
    }
    
    // dL/db = dL/dout * a
    if(b->requires_grad) {
        for(int i = 0; i < b->size; i++) {
            b->grad[i] += out->grad[i] * a->data[i];
        }
    }
}
\end{lstlisting}

\section{Topological Sort e Propagação Reversa}

\begin{lstlisting}[language=C, caption=Backward recursivo com ordenação topológica]
void tensor_backward(Tensor* loss) {
    if(!loss->requires_grad) return;
    
    // Inicializa gradiente da loss como 1 (dL/dL = 1)
    for(int i = 0; i < loss->size; i++) {
        loss->grad[i] = 1.0f;
    }
    
    // Coleta todos os nós do grafo via DFS
    AutogradNode** nodes = NULL;
    int n_nodes = 0;
    collect_nodes(loss->grad_node, &nodes, &n_nodes);
    
    // Ordenação topológica (DFS reversa)
    topological_sort(nodes, n_nodes);
    
    // Backward em ordem reversa
    for(int i = n_nodes - 1; i >= 0; i--) {
        if(nodes[i]->backward) {
            nodes[i]->backward(nodes[i]);
        }
    }
}

void collect_nodes(AutogradNode* node, AutogradNode*** nodes, int* n) {
    if(!node) return;
    
    // Evita duplicatas
    for(int i = 0; i < *n; i++) {
        if((*nodes)[i] == node) return;
    }
    
    // Adiciona à lista
    *nodes = realloc(*nodes, (*n + 1) * sizeof(AutogradNode*));
    (*nodes)[*n] = node;
    (*n)++;
    
    // Recursão nos pais
    for(int i = 0; i < node->n_parents; i++) {
        collect_nodes(node->parents[i], nodes, n);
    }
}
\end{lstlisting}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Camadas Avançadas e Funções de Ativação}

\section{Camada Linear (Fully Connected)}

\begin{lstlisting}[language=C, caption=Implementação completa da camada Linear]
typedef struct Linear {
    Tensor* weight;
    Tensor* bias;
    Tensor* output;
    Tensor* input_cache;
    
    int in_features;
    int out_features;
} Linear;

Linear* linear_create(int in_features, int out_features) {
    Linear* layer = (Linear*)malloc(sizeof(Linear));
    layer->in_features = in_features;
    layer->out_features = out_features;
    
    int w_shape[] = {out_features, in_features};
    layer->weight = tensor_create(w_shape, 2);
    init_weights_he(layer->weight, in_features);
    
    int b_shape[] = {out_features};
    layer->bias = tensor_create(b_shape, 1);
    for(int i = 0; i < out_features; i++) layer->bias->data[i] = 0;
    
    return layer;
}

Tensor* linear_forward(Linear* layer, Tensor* input) {
    // input shape: [batch_size, in_features]
    // output shape: [batch_size, out_features]
    
    int batch_size = input->shape[0];
    int out_shape[] = {batch_size, layer->out_features};
    
    if(!layer->output) {
        layer->output = tensor_create(out_shape, 2);
    }
    
    // y = x @ W^T + b
    tensor_matmul(input, layer->weight, layer->output, 1, 0); // Transpose W?
    
    // Adiciona bias (broadcasting)
    for(int i = 0; i < batch_size; i++) {
        for(int j = 0; j < layer->out_features; j++) {
            layer->output->data[i * layer->out_features + j] += 
                layer->bias->data[j];
        }
    }
    
    // Cache para backward
    layer->input_cache = input;
    
    return layer->output;
}

void linear_backward(Linear* layer, Tensor* grad_output) {
    // grad_output: [batch_size, out_features]
    int batch_size = grad_output->shape[0];
    
    // grad_weight = input^T @ grad_output
    if(layer->weight->requires_grad) {
        // grad_weight shape: [out_features, in_features]
        tensor_matmul_transpose(layer->input_cache, grad_output, 
                               layer->weight->grad, 1, 0);
    }
    
    // grad_bias = sum(grad_output, dim=0)
    if(layer->bias->requires_grad) {
        for(int j = 0; j < layer->out_features; j++) {
            float sum = 0;
            for(int i = 0; i < batch_size; i++) {
                sum += grad_output->data[i * layer->out_features + j];
            }
            layer->bias->grad[j] += sum;
        }
    }
    
    // grad_input = grad_output @ weight
    if(layer->input_cache->requires_grad) {
        tensor_matmul(grad_output, layer->weight, 
                     layer->input_cache->grad, 0, 1); // Transpose weight
    }
}
\end{lstlisting}

\section{Funções de Ativação com Autograd}

\subsection{ReLU e Leaky ReLU}

\begin{lstlisting}[language=C, caption=ReLU com autograd]
Tensor* relu_forward(Tensor* x) {
    Tensor* out = tensor_create_like(x);
    
    for(int i = 0; i < x->size; i++) {
        out->data[i] = x->data[i] > 0 ? x->data[i] : 0;
    }
    
    if(x->requires_grad) {
        out->requires_grad = 1;
        out->grad_node = autograd_node_create(OP_RELU, 1, &x);
        out->grad_node->backward = relu_backward;
        out->grad_node->op_ctx = (void*)x;  // Salva input para máscara
    }
    
    return out;
}

void relu_backward(AutogradNode* node) {
    Tensor* out = node->output;
    Tensor* x = (Tensor*)node->op_ctx;
    Tensor* grad_out = out->grad;  // dL/d(out)
    
    if(x->requires_grad) {
        for(int i = 0; i < x->size; i++) {
            if(x->data[i] > 0) {
                x->grad[i] += grad_out->data[i];
            }
        }
    }
}
\end{lstlisting}

\subsection{Softmax Estável Numericamente}

Softmax pode sofrer overflow/underflow. A versão estável subtrai o máximo:

\[
p_i = \frac{e^{z_i - \max(z)}}{\sum_j e^{z_j - \max(z)}}
\]

\begin{lstlisting}[language=C, caption=Softmax estável e seu gradiente]
Tensor* softmax_forward(Tensor* x, int dim) {
    // Assume x shape: [batch_size, n_classes]
    int batch_size = x->shape[0];
    int n_classes = x->shape[1];
    
    Tensor* out = tensor_create_like(x);
    
    for(int b = 0; b < batch_size; b++) {
        // Encontra máximo para estabilidade numérica
        float max_val = x->data[b * n_classes];
        for(int c = 1; c < n_classes; c++) {
            if(x->data[b * n_classes + c] > max_val) {
                max_val = x->data[b * n_classes + c];
            }
        }
        
        // Calcula exponenciais e soma
        float sum = 0;
        for(int c = 0; c < n_classes; c++) {
            int idx = b * n_classes + c;
            out->data[idx] = expf(x->data[idx] - max_val);
            sum += out->data[idx];
        }
        
        // Normaliza
        for(int c = 0; c < n_classes; c++) {
            out->data[b * n_classes + c] /= sum;
        }
    }
    
    return out;
}

Tensor* softmax_backward(Tensor* out, Tensor* grad_out) {
    // Jacobiana da softmax: p_i * (delta_ij - p_j)
    // dL/dx_i = sum_j (dL/dp_j * p_i * (delta_ij - p_j))
    // = p_i * (dL/dp_i - sum_j(dL/dp_j * p_j))
    
    int batch_size = out->shape[0];
    int n_classes = out->shape[1];
    
    Tensor* grad_in = tensor_create_like(out);
    
    for(int b = 0; b < batch_size; b++) {
        // Calcula dot product: sum(dL/dp_j * p_j)
        float dot = 0;
        for(int j = 0; j < n_classes; j++) {
            int idx = b * n_classes + j;
            dot += grad_out->data[idx] * out->data[idx];
        }
        
        for(int i = 0; i < n_classes; i++) {
            int idx = b * n_classes + i;
            grad_in->data[idx] = out->data[idx] * (grad_out->data[idx] - dot);
        }
    }
    
    return grad_in;
}
\end{lstlisting}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Redes Convolucionais: Implementação Profunda}

\section{Fundamentos da Convolução Discreta}

Convolução 2D discreta para imagens:
\[
(I * K)(i,j) = \sum_{m=0}^{M-1} \sum_{n=0}^{N-1} I(i+m, j+n) \cdot K(m,n)
\]

\subsection{Implementação Ingênua vs Otimizada}

\begin{lstlisting}[language=C, caption=Convolução 2D com 6 loops]
typedef struct Conv2D {
    Tensor* weight;  // [out_channels, in_channels, kernel_h, kernel_w]
    Tensor* bias;    // [out_channels]
    int stride;
    int padding;
    
    // Cache para backward
    Tensor* input;
    Tensor* output;
} Conv2D;

Tensor* conv2d_forward(Conv2D* layer, Tensor* input) {
    // input: [batch, in_channels, h, w]
    int batch = input->shape[0];
    int in_c = input->shape[1];
    int in_h = input->shape[2];
    int in_w = input->shape[3];
    
    int out_c = layer->weight->shape[0];
    int k_h = layer->weight->shape[2];
    int k_w = layer->weight->shape[3];
    
    // Calcula dimensões de saída
    int out_h = (in_h + 2*layer->padding - k_h) / layer->stride + 1;
    int out_w = (in_w + 2*layer->padding - k_w) / layer->stride + 1;
    
    int out_shape[] = {batch, out_c, out_h, out_w};
    Tensor* out = tensor_create(out_shape, 4);
    
    // Aplica padding se necessário
    Tensor* input_padded = input;
    if(layer->padding > 0) {
        input_padded = tensor_pad(input, layer->padding);
    }
    
    // 6 loops: batch, out_c, out_h, out_w, k_h, k_w
    for(int n = 0; n < batch; n++) {
        for(int oc = 0; oc < out_c; oc++) {
            for(int oh = 0; oh < out_h; oh++) {
                for(int ow = 0; ow < out_w; ow++) {
                    float sum = layer->bias->data[oc];
                    
                    for(int ic = 0; ic < in_c; ic++) {
                        for(int kh = 0; kh < k_h; kh++) {
                            for(int kw = 0; kw < k_w; kw++) {
                                int ih = oh * layer->stride + kh;
                                int iw = ow * layer->stride + kw;
                                
                                int in_idx = ((n * in_c + ic) * in_h + ih) * in_w + iw;
                                int w_idx = ((oc * in_c + ic) * k_h + kh) * k_w + kw;
                                
                                sum += input_padded->data[in_idx] * 
                                       layer->weight->data[w_idx];
                            }
                        }
                    }
                    
                    int out_idx = ((n * out_c + oc) * out_h + oh) * out_w + ow;
                    out->data[out_idx] = sum;
                }
            }
        }
    }
    
    if(layer->padding > 0) {
        tensor_free(input_padded);
    }
    
    return out;
}
\end{lstlisting}

\section{Backpropagation em Convolução}

O backward da convolução é notoriamente complexo. Podemos implementar como convolução com rotação de kernels.

\begin{lstlisting}[language=C, caption=Backward da convolução]
void conv2d_backward(Conv2D* layer, Tensor* grad_output) {
    // grad_output: [batch, out_c, out_h, out_w]
    int batch = grad_output->shape[0];
    int out_c = grad_output->shape[1];
    int out_h = grad_output->shape[2];
    int out_w = grad_output->shape[3];
    
    // grad_weight: rotacionar input e convoluir com grad_output
    if(layer->weight->requires_grad) {
        // Inicializa grad_weight com zeros
        for(int i = 0; i < layer->weight->size; i++) {
            layer->weight->grad[i] = 0;
        }
        
        for(int n = 0; n < batch; n++) {
            for(int oc = 0; oc < out_c; oc++) {
                for(int ic = 0; ic < layer->weight->shape[1]; ic++) {
                    for(int kh = 0; kh < layer->weight->shape[2]; kh++) {
                        for(int kw = 0; kw < layer->weight->shape[3]; kw++) {
                            float sum = 0;
                            
                            for(int oh = 0; oh < out_h; oh++) {
                                for(int ow = 0; ow < out_w; ow++) {
                                    int ih = oh * layer->stride + kh;
                                    int iw = ow * layer->stride + kw;
                                    
                                    int in_idx = ((n * layer->weight->shape[1] + ic) * 
                                                 layer->input->shape[2] + ih) * 
                                                 layer->input->shape[3] + iw;
                                    int out_idx = ((n * out_c + oc) * out_h + oh) * out_w + ow;
                                    
                                    sum += layer->input->data[in_idx] * 
                                           grad_output->data[out_idx];
                                }
                            }
                            
                            int w_idx = ((oc * layer->weight->shape[1] + ic) * 
                                        layer->weight->shape[2] + kh) * 
                                        layer->weight->shape[3] + kw;
                            layer->weight->grad[w_idx] += sum;
                        }
                    }
                }
            }
        }
    }
    
    // grad_bias: soma sobre batch, altura, largura
    if(layer->bias->requires_grad) {
        for(int oc = 0; oc < out_c; oc++) {
            float sum = 0;
            for(int n = 0; n < batch; n++) {
                for(int oh = 0; oh < out_h; oh++) {
                    for(int ow = 0; ow < out_w; ow++) {
                        int idx = ((n * out_c + oc) * out_h + oh) * out_w + ow;
                        sum += grad_output->data[idx];
                    }
                }
            }
            layer->bias->grad[oc] += sum;
        }
    }
    
    // grad_input: convolução transposta (full convolution)
    if(layer->input->requires_grad) {
        // Implementar conv2d_transpose
        Tensor* grad_input = conv2d_transpose(grad_output, layer->weight, 
                                              layer->stride, layer->padding);
        // Acumular em layer->input->grad
        tensor_add_to(grad_input, layer->input->grad);
        tensor_free(grad_input);
    }
}
\end{lstlisting}

\section{Otimizações: Im2Col e GEMM}

A abordagem de 6 loops é muito lenta. Podemos converter convolução em multiplicação de matrizes:

\begin{lstlisting}[language=C, caption=Algoritmo im2col para convolução otimizada]
Tensor* im2col(Tensor* im, int k_h, int k_w, int stride, int pad) {
    // im: [batch, channels, h, w]
    int batch = im->shape[0];
    int channels = im->shape[1];
    int h = im->shape[2];
    int w = im->shape[3];
    
    int out_h = (h + 2*pad - k_h) / stride + 1;
    int out_w = (w + 2*pad - k_w) / stride + 1;
    
    // Matriz de saída: [batch * out_h * out_w, channels * k_h * k_w]
    int col_shape[] = {batch * out_h * out_w, channels * k_h * k_w};
    Tensor* col = tensor_create(col_shape, 2);
    
    for(int b = 0; b < batch; b++) {
        for(int oh = 0; oh < out_h; oh++) {
            for(int ow = 0; ow < out_w; ow++) {
                int row_idx = (b * out_h + oh) * out_w + ow;
                
                for(int c = 0; c < channels; c++) {
                    for(int kh = 0; kh < k_h; kh++) {
                        for(int kw = 0; kw < k_w; kw++) {
                            int ih = oh * stride + kh - pad;
                            int iw = ow * stride + kw - pad;
                            
                            float val = 0;
                            if(ih >= 0 && ih < h && iw >= 0 && iw < w) {
                                int im_idx = ((b * channels + c) * h + ih) * w + iw;
                                val = im->data[im_idx];
                            }
                            
                            int col_idx = row_idx * col->shape[1] + 
                                         ((c * k_h + kh) * k_w + kw);
                            col->data[col_idx] = val;
                        }
                    }
                }
            }
        }
    }
    
    return col;
}

Tensor* conv2d_im2col(Conv2D* layer, Tensor* input) {
    // Converte para multiplicação de matrizes
    Tensor* col = im2col(input, layer->weight->shape[2], 
                        layer->weight->shape[3], 
                        layer->stride, layer->padding);
    
    // weight: [out_c, in_c * k_h * k_w]
    int w_shape[] = {layer->weight->shape[0], 
                     layer->weight->shape[1] * 
                     layer->weight->shape[2] * 
                     layer->weight->shape[3]};
    Tensor* w_flat = tensor_reshape(layer->weight, w_shape, 2);
    
    // output = col @ w_flat^T
    int out_shape[] = {input->shape[0], 
                       layer->weight->shape[0],
                       col->shape[0] / input->shape[0], 1}; // Ajustar
    Tensor* out = tensor_matmul(col, w_flat, 0, 1);
    
    // Adicionar bias e reshape
    
    tensor_free(col);
    return out;
}
\end{lstlisting}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Otimizadores: Teoria e Implementação}

\section{Stochastic Gradient Descent (SGD)}

\subsection{Com e sem Momentum}

Momentum acumula gradientes passados:
\[
v_t = \mu v_{t-1} + \eta \nabla L(\theta_t)
\]
\[
\theta_{t+1} = \theta_t - v_t
\]

\begin{lstlisting}[language=C, caption=SGD com momentum]
typedef struct SGD {
    float lr;
    float momentum;
    float weight_decay;
    
    // Velocidades para cada tensor
    Tensor** velocities;
    int n_params;
} SGD;

SGD* sgd_create(float lr, float momentum, float weight_decay) {
    SGD* opt = (SGD*)malloc(sizeof(SGD));
    opt->lr = lr;
    opt->momentum = momentum;
    opt->weight_decay = weight_decay;
    opt->velocities = NULL;
    opt->n_params = 0;
    return opt;
}

void sgd_add_param(SGD* opt, Tensor* param) {
    opt->n_params++;
    opt->velocities = realloc(opt->velocities, 
                             opt->n_params * sizeof(Tensor*));
    
    int idx = opt->n_params - 1;
    opt->velocities[idx] = tensor_create_like(param);
    // Inicializa velocidades com zero
    memset(opt->velocities[idx]->data, 0, 
           opt->velocities[idx]->size * sizeof(float));
}

void sgd_step(SGD* opt) {
    for(int i = 0; i < opt->n_params; i++) {
        Tensor* param = opt->velocities[i]; // Na verdade param
        Tensor* vel = opt->velocities[i];
        
        for(int j = 0; j < param->size; j++) {
            // weight decay: adiciona penalidade L2
            float grad = param->grad[j];
            if(opt->weight_decay > 0) {
                grad += opt->weight_decay * param->data[j];
            }
            
            // momentum
            vel->data[j] = opt->momentum * vel->data[j] + opt->lr * grad;
            
            // update
            param->data[j] -= vel->data[j];
        }
    }
}
\end{lstlisting}

\section{Adam: Adaptive Moment Estimation}

Adam combina momentum com adaptação de taxa de aprendizado por parâmetro:

\begin{align*}
m_t &= \beta_1 m_{t-1} + (1-\beta_1) g_t \\
v_t &= \beta_2 v_{t-1} + (1-\beta_2) g_t^2 \\
\hat{m}_t &= \frac{m_t}{1-\beta_1^t} \\
\hat{v}_t &= \frac{v_t}{1-\beta_2^t} \\
\theta_{t+1} &= \theta_t - \eta \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}
\end{align*}

\begin{lstlisting}[language=C, caption=Implementação completa do Adam]
typedef struct Adam {
    float lr;
    float beta1;
    float beta2;
    float eps;
    
    Tensor** m;  // Primeiro momento
    Tensor** v;  // Segundo momento
    int* t;      // Timestep para cada parâmetro
    int n_params;
} Adam;

Adam* adam_create(float lr, float beta1, float beta2, float eps) {
    Adam* opt = (Adam*)malloc(sizeof(Adam));
    opt->lr = lr;
    opt->beta1 = beta1;
    opt->beta2 = beta2;
    opt->eps = eps;
    opt->m = NULL;
    opt->v = NULL;
    opt->t = NULL;
    opt->n_params = 0;
    return opt;
}

void adam_add_param(Adam* opt, Tensor* param) {
    opt->n_params++;
    opt->m = realloc(opt->m, opt->n_params * sizeof(Tensor*));
    opt->v = realloc(opt->v, opt->n_params * sizeof(Tensor*));
    opt->t = realloc(opt->t, opt->n_params * sizeof(int));
    
    int idx = opt->n_params - 1;
    opt->m[idx] = tensor_create_like(param);
    opt->v[idx] = tensor_create_like(param);
    memset(opt->m[idx]->data, 0, opt->m[idx]->size * sizeof(float));
    memset(opt->v[idx]->data, 0, opt->v[idx]->size * sizeof(float));
    opt->t[idx] = 0;
}

void adam_step(Adam* opt) {
    for(int i = 0; i < opt->n_params; i++) {
        Tensor* param = /* ... */;
        Tensor* m = opt->m[i];
        Tensor* v = opt->v[i];
        opt->t[i]++;
        
        float bias_correction1 = 1.0f - powf(opt->beta1, opt->t[i]);
        float bias_correction2 = 1.0f - powf(opt->beta2, opt->t[i]);
        
        for(int j = 0; j < param->size; j++) {
            float g = param->grad[j];
            
            // Atualiza momentos
            m->data[j] = opt->beta1 * m->data[j] + (1 - opt->beta1) * g;
            v->data[j] = opt->beta2 * v->data[j] + (1 - opt->beta2) * g * g;
            
            // Correção de viés
            float m_hat = m->data[j] / bias_correction1;
            float v_hat = v->data[j] / bias_correction2;
            
            // Atualiza parâmetro
            param->data[j] -= opt->lr * m_hat / (sqrtf(v_hat) + opt->eps);
        }
    }
}
\end{lstlisting}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Treinamento e Validação}

\section{DataLoader e Batching}

\begin{lstlisting}[language=C, caption=DataLoader com shuffle]
typedef struct Dataset {
    Tensor* data;
    Tensor* targets;
    int size;
} Dataset;

typedef struct DataLoader {
    Dataset* dataset;
    int batch_size;
    int* indices;
    int current_idx;
    int shuffle;
} DataLoader;

DataLoader* dataloader_create(Dataset* dataset, int batch_size, int shuffle) {
    DataLoader* dl = (DataLoader*)malloc(sizeof(DataLoader));
    dl->dataset = dataset;
    dl->batch_size = batch_size;
    dl->shuffle = shuffle;
    dl->current_idx = 0;
    
    dl->indices = (int*)malloc(dataset->size * sizeof(int));
    for(int i = 0; i < dataset->size; i++) {
        dl->indices[i] = i;
    }
    
    if(shuffle) {
        for(int i = dataset->size - 1; i > 0; i--) {
            int j = rand() % (i + 1);
            int temp = dl->indices[i];
            dl->indices[i] = dl->indices[j];
            dl->indices[j] = temp;
        }
    }
    
    return dl;
}

int dataloader_next_batch(DataLoader* dl, Tensor** batch_data, Tensor** batch_targets) {
    if(dl->current_idx >= dl->dataset->size) {
        dl->current_idx = 0;
        if(dl->shuffle) {
            // Reshuffle
        }
        return 0;
    }
    
    int batch_end = dl->current_idx + dl->batch_size;
    if(batch_end > dl->dataset->size) {
        batch_end = dl->dataset->size;
    }
    int current_batch_size = batch_end - dl->current_idx;
    
    // Alocar tensores do batch
    int data_shape[] = {current_batch_size, 
                        dl->dataset->data->shape[1]}; // Simplificado
    *batch_data = tensor_create(data_shape, 2);
    
    int target_shape[] = {current_batch_size, 
                          dl->dataset->targets->shape[1]};
    *batch_targets = tensor_create(target_shape, 2);
    
    // Copiar dados
    for(int i = 0; i < current_batch_size; i++) {
        int idx = dl->indices[dl->current_idx + i];
        
        // Copiar features
        for(int j = 0; j < dl->dataset->data->shape[1]; j++) {
            (*batch_data)->data[i * dl->dataset->data->shape[1] + j] = 
                dl->dataset->data->data[idx * dl->dataset->data->shape[1] + j];
        }
        
        // Copiar targets
        for(int j = 0; j < dl->dataset->targets->shape[1]; j++) {
            (*batch_targets)->data[i * dl->dataset->targets->shape[1] + j] = 
                dl->dataset->targets->data[idx * dl->dataset->targets->shape[1] + j];
        }
    }
    
    dl->current_idx = batch_end;
    return current_batch_size;
}
\end{lstlisting}

\section{Loop de Treinamento Completo}

\begin{lstlisting}[language=C, caption=Training loop profissional]
typedef struct Trainer {
    MLP* model;
    Optimizer* optimizer;
    float (*loss_fn)(Tensor*, Tensor*);
    void (*loss_backward)(Tensor*, Tensor*);
    
    float train_loss;
    float val_loss;
    float train_acc;
    float val_acc;
} Trainer;

void trainer_train_epoch(Trainer* trainer, DataLoader* train_loader) {
    float total_loss = 0;
    int total_correct = 0;
    int total_samples = 0;
    
    while(1) {
        Tensor* batch_x;
        Tensor* batch_y;
        int batch_size = dataloader_next_batch(train_loader, &batch_x, &batch_y);
        if(batch_size == 0) break;
        
        // Forward pass
        Tensor* output = mlp_forward(trainer->model, batch_x);
        
        // Compute loss
        float loss = trainer->loss_fn(output, batch_y);
        total_loss += loss * batch_size;
        
        // Compute accuracy
        int correct = compute_accuracy(output, batch_y);
        total_correct += correct;
        total_samples += batch_size;
        
        // Backward pass
        trainer->loss_backward(output, batch_y);
        tensor_backward(output);
        
        // Update weights
        optimizer_step(trainer->optimizer);
        
        // Zero gradients
        optimizer_zero_grad(trainer->optimizer);
        
        // Cleanup
        tensor_free(batch_x);
        tensor_free(batch_y);
        tensor_free(output);
    }
    
    trainer->train_loss = total_loss / total_samples;
    trainer->train_acc = (float)total_correct / total_samples;
    
    printf("Train Loss: %.4f, Train Acc: %.4f\n", 
           trainer->train_loss, trainer->train_acc);
}

void trainer_validate(Trainer* trainer, DataLoader* val_loader) {
    // Similar ao train, mas sem gradientes e updates
    // ...
}
\end{lstlisting}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Serialização e Persistência de Modelos}

\section{Salvando e Carregando Modelos}

Formato binário portável com metadados:

\begin{lstlisting}[language=C, caption=Save/Load completo]
typedef struct ModelHeader {
    char magic[4];  // "DLFW"
    int version;
    int n_layers;
    int model_type;
    int data_size;
} ModelHeader;

void model_save(MLP* model, const char* filename) {
    FILE* fp = fopen(filename, "wb");
    
    // Header
    ModelHeader header = {
        .magic = {'D','L','F','W'},
        .version = 1,
        .n_layers = model->n_layers,
        .model_type = 0,
        .data_size = 0
    };
    
    // Calcular tamanho total
    for(int i = 0; i < model->n_layers; i++) {
        if(model->layers[i]->weights) {
            header.data_size += model->layers[i]->weights->size * sizeof(float);
            header.data_size += model->layers[i]->bias->size * sizeof(float);
        }
    }
    
    fwrite(&header, sizeof(ModelHeader), 1, fp);
    
    // Salvar arquitetura
    for(int i = 0; i < model->n_layers; i++) {
        Layer* layer = model->layers[i];
        
        // Tipo da camada
        int layer_type = 0; // 0: linear, 1: conv2d, etc.
        fwrite(&layer_type, sizeof(int), 1, fp);
        
        // Parâmetros da camada
        int in_features = layer->weights->shape[1];
        int out_features = layer->weights->shape[0];
        fwrite(&in_features, sizeof(int), 1, fp);
        fwrite(&out_features, sizeof(int), 1, fp);
        
        // Ativação
        fwrite(&layer->activation, sizeof(char), 1, fp);
        
        // Pesos e bias
        fwrite(layer->weights->data, sizeof(float), 
               layer->weights->size, fp);
        fwrite(layer->bias->data, sizeof(float), 
               layer->bias->size, fp);
    }
    
    fclose(fp);
}

MLP* model_load(const char* filename) {
    FILE* fp = fopen(filename, "rb");
    
    // Ler header
    ModelHeader header;
    fread(&header, sizeof(ModelHeader), 1, fp);
    
    if(header.magic[0] != 'D' || header.magic[1] != 'L' ||
       header.magic[2] != 'F' || header.magic[3] != 'W') {
        printf("Formato de arquivo inválido\n");
        return NULL;
    }
    
    // Reconstruir modelo
    MLP* model = mlp_create();
    
    for(int i = 0; i < header.n_layers; i++) {
        int layer_type;
        fread(&layer_type, sizeof(int), 1, fp);
        
        int in_features, out_features;
        fread(&in_features, sizeof(int), 1, fp);
        fread(&out_features, sizeof(int), 1, fp);
        
        char activation;
        fread(&activation, sizeof(char), 1, fp);
        
        Layer* layer = layer_create(in_features, out_features);
        layer->activation = activation;
        
        // Carregar pesos
        fread(layer->weights->data, sizeof(float), 
              layer->weights->size, fp);
        fread(layer->bias->data, sizeof(float), 
              layer->bias->size, fp);
        
        mlp_add_layer(model, layer);
    }
    
    fclose(fp);
    return model;
}
\end{lstlisting}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Estudos de Caso e Projetos Práticos}

\section{Exemplo 1: MNIST do Zero}

Implementação completa de reconhecimento de dígitos:

\begin{lstlisting}[language=C, caption=MNIST pipeline completo]
int main() {
    // 1. Carregar dados
    Dataset* train_dataset = mnist_load("train-images.idx3-ubyte", 
                                        "train-labels.idx1-ubyte");
    Dataset* test_dataset = mnist_load("t10k-images.idx3-ubyte", 
                                       "t10k-labels.idx1-ubyte");
    
    // 2. Criar modelo
    MLP* model = mlp_create();
    mlp_add_layer(model, linear_create(784, 256));
    mlp_add_layer(model, relu_create());
    mlp_add_layer(model, linear_create(256, 128));
    mlp_add_layer(model, relu_create());
    mlp_add_layer(model, linear_create(128, 10));
    mlp_add_layer(model, softmax_create());
    
    // 3. Configurar treinamento
    Adam* optimizer = adam_create(0.001, 0.9, 0.999, 1e-8);
    mlp_add_parameters(model, optimizer);
    
    Trainer* trainer = trainer_create(model, optimizer, 
                                      cross_entropy_loss, 
                                      cross_entropy_backward);
    
    // 4. Loop de treinamento
    DataLoader* train_loader = dataloader_create(train_dataset, 64, 1);
    DataLoader* test_loader = dataloader_create(test_dataset, 64, 0);
    
    for(int epoch = 0; epoch < 10; epoch++) {
        trainer_train_epoch(trainer, train_loader);
        trainer_validate(trainer, test_loader);
        
        printf("Epoch %d: Train Acc: %.4f, Test Acc: %.4f\n", 
               epoch, trainer->train_acc, trainer->val_acc);
    }
    
    // 5. Salvar modelo treinado
    model_save(model, "mnist_model.dlfw");
    
    return 0;
}
\end{lstlisting}

\section{Exemplo 2: CNN para CIFAR-10}

\begin{lstlisting}[language=C, caption=CNN completa para CIFAR-10]
Model* create_cifar10_cnn() {
    Model* model = model_create();
    
    // Conv1: 32x32x3 -> 32x32x32
    model_add(model, conv2d_create(3, 32, 3, 1, 1));
    model_add(model, batch_norm_create(32));
    model_add(model, relu_create());
    model_add(model, maxpool2d_create(2, 2));
    
    // Conv2: 16x16x32 -> 16x16x64
    model_add(model, conv2d_create(32, 64, 3, 1, 1));
    model_add(model, batch_norm_create(64));
    model_add(model, relu_create());
    model_add(model, maxpool2d_create(2, 2));
    
    // Conv3: 8x8x64 -> 8x8x128
    model_add(model, conv2d_create(64, 128, 3, 1, 1));
    model_add(model, batch_norm_create(128));
    model_add(model, relu_create());
    
    // Global average pooling
    model_add(model, global_avgpool2d_create());
    
    // Classifier
    model_add(model, linear_create(128, 256));
    model_add(model, relu_create());
    model_add(model, dropout_create(0.5));
    model_add(model, linear_create(256, 10));
    model_add(model, softmax_create());
    
    return model;
}
\end{lstlisting}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Otimizações Avançadas e Performance}

\section{BLAS-Level Optimizations}

\subsection{Tiling para Cache L1/L2}

\begin{lstlisting}[language=C, caption=Multiplicação de matrizes com tiling]
#define BLOCK_SIZE 32

void matmul_tiled(Tensor* a, Tensor* b, Tensor* out, 
                  int M, int N, int K) {
    
    for(int i = 0; i < M; i += BLOCK_SIZE) {
        for(int j = 0; j < N; j += BLOCK_SIZE) {
            for(int k = 0; k < K; k += BLOCK_SIZE) {
                
                // Processa block (i,i+BS) x (k,k+BS) * (k,k+BS) x (j,j+BS)
                for(int ii = i; ii < i + BLOCK_SIZE && ii < M; ii++) {
                    for(int jj = j; jj < j + BLOCK_SIZE && jj < N; jj++) {
                        float sum = out->data[ii * N + jj];
                        
                        for(int kk = k; kk < k + BLOCK_SIZE && kk < K; kk++) {
                            sum += a->data[ii * K + kk] * b->data[kk * N + jj];
                        }
                        
                        out->data[ii * N + jj] = sum;
                    }
                }
            }
        }
    }
}
\end{lstlisting}

\subsection{SIMD Intrinsics}

\begin{lstlisting}[language=C, caption=Usando SSE/AVX para operações vetoriais]
#include <immintrin.h>

void tensor_add_simd(float* a, float* b, float* out, int n) {
    int i = 0;
    
    #ifdef __AVX__
    // Processa 8 floats por vez com AVX
    for(; i <= n - 8; i += 8) {
        __m256 va = _mm256_loadu_ps(&a[i]);
        __m256 vb = _mm256_loadu_ps(&b[i]);
        __m256 vout = _mm256_add_ps(va, vb);
        _mm256_storeu_ps(&out[i], vout);
    }
    #elif __SSE__
    // Processa 4 floats por vez com SSE
    for(; i <= n - 4; i += 4) {
        __m128 va = _mm_loadu_ps(&a[i]);
        __m128 vb = _mm_loadu_ps(&b[i]);
        __m128 vout = _mm_add_ps(va, vb);
        _mm_storeu_ps(&out[i], vout);
    }
    #endif
    
    // Processa o restante
    for(; i < n; i++) {
        out[i] = a[i] + b[i];
    }
}
\end{lstlisting}

\section{Parallelism with OpenMP}

\begin{lstlisting}[language=C, caption=Paralelização de operações]
#include <omp.h>

void conv2d_parallel(Conv2D* layer, Tensor* input, Tensor* output) {
    int batch = input->shape[0];
    int out_c = output->shape[1];
    int out_h = output->shape[2];
    int out_w = output->shape[3];
    
    #pragma omp parallel for collapse(4) schedule(dynamic)
    for(int n = 0; n < batch; n++) {
        for(int oc = 0; oc < out_c; oc++) {
            for(int oh = 0; oh < out_h; oh++) {
                for(int ow = 0; ow < out_w; ow++) {
                    // Cálculo da convolução
                    // ...
                }
            }
        }
    }
}
\end{lstlisting}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Próximos Passos: Além do Framework}

\section{Suporte a GPU com CUDA}

\begin{lstlisting}[language=C, caption=Interface CUDA para operações]
#ifdef USE_CUDA
#include <cuda_runtime.h>

__global__ void relu_kernel(float* x, float* out, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if(idx < n) {
        out[idx] = x[idx] > 0 ? x[idx] : 0;
    }
}

void relu_cuda(Tensor* x, Tensor* out) {
    float* d_x, d_out;
    
    // Alocar memória na GPU
    cudaMalloc(&d_x, x->size * sizeof(float));
    cudaMalloc(&d_out, out->size * sizeof(float));
    
    // Copiar dados para GPU
    cudaMemcpy(d_x, x->data, x->size * sizeof(float), 
               cudaMemcpyHostToDevice);
    
    // Lançar kernel
    int block_size = 256;
    int num_blocks = (x->size + block_size - 1) / block_size;
    relu_kernel<<<num_blocks, block_size>>>(d_x, d_out, x->size);
    
    // Copiar resultado de volta
    cudaMemcpy(out->data, d_out, out->size * sizeof(float), 
               cudaMemcpyDeviceToHost);
    
    // Liberar memória
    cudaFree(d_x);
    cudaFree(d_out);
}
#endif
\end{lstlisting}

\section{Implementação de Transformers}

Arquitetura completa de Transformer para processamento de sequências:

\begin{itemize}
    \item Multi-Head Self-Attention
    \item Positional Encoding
    \item Feed-Forward Networks
    \item Layer Normalization
    \item Residual Connections
\end{itemize}

\section{Mixed Precision Training}

Implementação de treinamento com FP16 para maior performance:

\begin{lstlisting}[language=C, caption=Cast de precisão mista]
void convert_to_fp16(float* fp32, __fp16* fp16, int n) {
    for(int i = 0; i < n; i++) {
        fp16[i] = (__fp16)fp32[i];
    }
}

void convert_to_fp32(__fp16* fp16, float* fp32, int n) {
    for(int i = 0; i < n; i++) {
        fp32[i] = (float)fp16[i];
    }
}

void matmul_mixed(Tensor* a_fp32, Tensor* b_fp32, Tensor* out_fp32) {
    // Converter para FP16
    __fp16* a_fp16 = malloc(a_fp32->size * sizeof(__fp16));
    __fp16* b_fp16 = malloc(b_fp32->size * sizeof(__fp16));
    
    convert_to_fp16(a_fp32->data, a_fp16, a_fp32->size);
    convert_to_fp16(b_fp32->data, b_fp16, b_fp32->size);
    
    // Multiplicação em FP16 (usando hardware nativo)
    __fp16* out_fp16 = malloc(out_fp32->size * sizeof(__fp16));
    matmul_fp16(a_fp16, b_fp16, out_fp16, /* dims */);
    
    // Converter de volta
    convert_to_fp32(out_fp16, out_fp32->data, out_fp32->size);
    
    free(a_fp16);
    free(b_fp16);
    free(out_fp16);
}
\end{lstlisting}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{Conclusão}

Você agora tem em mãos um framework completo de deep learning implementado em C puro, com:

\begin{itemize}
    \item Sistema de tensores com gerenciamento de memória
    \item Autograd com grafo computacional dinâmico
    \item Camadas: Linear, Conv2D, BatchNorm, Dropout
    \item Ativações: ReLU, Sigmoid, Tanh, Softmax
    \item Otimizadores: SGD, Adam
    \item Funções de custo: MSE, Cross-Entropy
    \item DataLoaders e batching
    \item Serialização de modelos
    \item Otimizações de performance: SIMD, OpenMP, CUDA
\end{itemize}

Este código é completamente funcional e pode ser usado para treinar redes neurais reais em problemas como MNIST, CIFAR-10, e até mesmo tarefas mais complexas.

O próximo passo é expandir para arquiteturas modernas como Transformers, GANs, e modelos de difusão, sempre mantendo a filosofia de implementar cada detalhe do zero para compreensão profunda.

\vspace{1cm}
\noindent
\textbf{A jornada continua...}

\end{document}