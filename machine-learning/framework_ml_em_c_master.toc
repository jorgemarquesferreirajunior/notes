\babel@toc {portuguese}{}\relax 
\contentsline {chapter}{\numberline {1}Fundamentos Matematicos e Teoricos do Aprendizado}{9}{chapter.1}%
\contentsline {section}{\numberline {1.1}O Problema Fundamental do Aprendizado}{9}{section.1.1}%
\contentsline {subsection}{\numberline {1.1.1}Espaco de Hipoteses e Capacidade}{9}{subsection.1.1.1}%
\contentsline {section}{\numberline {1.2}Deducao Detalhada da Funcao de Custo}{10}{section.1.2}%
\contentsline {subsection}{\numberline {1.2.1}Mean Squared Error (MSE)}{10}{subsection.1.2.1}%
\contentsline {subsection}{\numberline {1.2.2}Cross-Entropy para Classificacao}{10}{subsection.1.2.2}%
\contentsline {section}{\numberline {1.3}Otimizacao e Gradiente Descendente}{11}{section.1.3}%
\contentsline {subsection}{\numberline {1.3.1}Deducao do Gradiente}{11}{subsection.1.3.1}%
\contentsline {subsection}{\numberline {1.3.2}Analise de Convergencia}{11}{subsection.1.3.2}%
\contentsline {section}{\numberline {1.4}Regra da Cadeia Vetorial e Jacobianos}{12}{section.1.4}%
\contentsline {subsection}{\numberline {1.4.1}Diferenca entre Gradiente e Jacobiano}{12}{subsection.1.4.1}%
\contentsline {chapter}{\numberline {2}Implementacao Base em C: Estruturas e Gerenciamento de Memoria}{13}{chapter.2}%
\contentsline {section}{\numberline {2.1}Gerenciamento de Memoria para Tensores}{13}{section.2.1}%
\contentsline {section}{\numberline {2.2}Funcoes de Criacao e Destruicao}{14}{section.2.2}%
\contentsline {section}{\numberline {2.3}Operacoes Basicas Otimizadas}{15}{section.2.3}%
\contentsline {section}{\numberline {2.4}Produto Matricial Otimizado}{15}{section.2.4}%
\contentsline {section}{\numberline {2.5}Estrategias de Otimizacao de Memoria}{16}{section.2.5}%
\contentsline {subsection}{\numberline {2.5.1}Pooling de Alocacao}{16}{subsection.2.5.1}%
\contentsline {chapter}{\numberline {3}Rede Neural: Matematica e Implementacao Detalhada}{17}{chapter.3}%
\contentsline {section}{\numberline {3.1}Arquitetura de uma Rede Neural}{17}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1}Neuronio Artificial: Modelo Matematico}{17}{subsection.3.1.1}%
\contentsline {section}{\numberline {3.2}Backpropagation: Deducao Passo a Passo}{18}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Caso Simples: 2 Camadas}{18}{subsection.3.2.1}%
\contentsline {subsubsection}{Derivadas da Camada de Saida}{18}{section*.3}%
\contentsline {subsubsection}{Derivadas da Camada Oculta}{18}{section*.4}%
\contentsline {subsection}{\numberline {3.2.2}Implementacao Completa do Backprop}{19}{subsection.3.2.2}%
\contentsline {section}{\numberline {3.3}Inicializacao de Pesos}{20}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}Xavier/Glorot Initialization}{20}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}He Initialization}{20}{subsection.3.3.2}%
\contentsline {chapter}{\numberline {4}Sistema de Autograd Completo}{23}{chapter.4}%
\contentsline {section}{\numberline {4.1}Arquitetura do Grafo Computacional}{23}{section.4.1}%
\contentsline {section}{\numberline {4.2}Implementacao de Operacoes com Grafo}{24}{section.4.2}%
\contentsline {section}{\numberline {4.3}Topological Sort e Propagacao Reversa}{25}{section.4.3}%
\contentsline {chapter}{\numberline {5}Camadas Avancadas e Funcoes de Ativacao}{27}{chapter.5}%
\contentsline {section}{\numberline {5.1}Camada Linear (Fully Connected)}{27}{section.5.1}%
\contentsline {section}{\numberline {5.2}Funcoes de Ativacao com Autograd}{29}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1}ReLU e Leaky ReLU}{29}{subsection.5.2.1}%
\contentsline {subsection}{\numberline {5.2.2}Softmax Estavel Numericamente}{30}{subsection.5.2.2}%
\contentsline {chapter}{\numberline {6}Redes Convolucionais: Implementacao Profunda}{33}{chapter.6}%
\contentsline {section}{\numberline {6.1}Fundamentos da Convolucao Discreta}{33}{section.6.1}%
\contentsline {subsection}{\numberline {6.1.1}Implementacao IngÃªnua vs Otimizada}{33}{subsection.6.1.1}%
\contentsline {section}{\numberline {6.2}Backpropagation em Convolucao}{35}{section.6.2}%
\contentsline {section}{\numberline {6.3}Otimizacoes: Im2Col e GEMM}{37}{section.6.3}%
\contentsline {chapter}{\numberline {7}Otimizadores: Teoria e Implementacao}{41}{chapter.7}%
\contentsline {section}{\numberline {7.1}Stochastic Gradient Descent (SGD)}{41}{section.7.1}%
\contentsline {subsection}{\numberline {7.1.1}Com e sem Momentum}{41}{subsection.7.1.1}%
\contentsline {section}{\numberline {7.2}Adam: Adaptive Moment Estimation}{43}{section.7.2}%
\contentsline {chapter}{\numberline {8}Treinamento e Validacao}{45}{chapter.8}%
\contentsline {section}{\numberline {8.1}DataLoader e Batching}{45}{section.8.1}%
\contentsline {section}{\numberline {8.2}Loop de Treinamento Completo}{47}{section.8.2}%
\contentsline {chapter}{\numberline {9}Serializacao e Persistencia de Modelos}{49}{chapter.9}%
\contentsline {section}{\numberline {9.1}Salvando e Carregando Modelos}{49}{section.9.1}%
\contentsline {chapter}{\numberline {10}Estudos de Caso e Projetos Praticos}{53}{chapter.10}%
\contentsline {section}{\numberline {10.1}Exemplo 1: MNIST do Zero}{53}{section.10.1}%
\contentsline {section}{\numberline {10.2}Exemplo 2: CNN para CIFAR-10}{54}{section.10.2}%
\contentsline {chapter}{\numberline {11}Otimizacoes Avancadas e Performance}{57}{chapter.11}%
\contentsline {section}{\numberline {11.1}BLAS-Level Optimizations}{57}{section.11.1}%
\contentsline {subsection}{\numberline {11.1.1}Tiling para Cache L1/L2}{57}{subsection.11.1.1}%
\contentsline {subsection}{\numberline {11.1.2}SIMD Intrinsics}{58}{subsection.11.1.2}%
\contentsline {section}{\numberline {11.2}Parallelism with OpenMP}{59}{section.11.2}%
\contentsline {chapter}{\numberline {12}Proximos Passos: Alem do Framework}{61}{chapter.12}%
\contentsline {section}{\numberline {12.1}Suporte a GPU com CUDA}{61}{section.12.1}%
\contentsline {section}{\numberline {12.2}Implementacao de Transformers}{62}{section.12.2}%
\contentsline {section}{\numberline {12.3}Mixed Precision Training}{62}{section.12.3}%
