\contentsline {chapter}{\numberline {1}Fundamentos Matemáticos e Teóricos do Aprendizado}{7}{chapter.1}%
\contentsline {section}{\numberline {1.1}O Problema Fundamental do Aprendizado}{7}{section.1.1}%
\contentsline {subsection}{\numberline {1.1.1}Espaço de Hipóteses e Capacidade}{7}{subsection.1.1.1}%
\contentsline {section}{\numberline {1.2}Derivação Detalhada da Função de Custo}{8}{section.1.2}%
\contentsline {subsection}{\numberline {1.2.1}Mean Squared Error (MSE)}{8}{subsection.1.2.1}%
\contentsline {subsection}{\numberline {1.2.2}Cross-Entropy para Classificação}{8}{subsection.1.2.2}%
\contentsline {section}{\numberline {1.3}Otimização e Gradiente Descendente}{9}{section.1.3}%
\contentsline {subsection}{\numberline {1.3.1}Derivação do Gradiente}{9}{subsection.1.3.1}%
\contentsline {subsection}{\numberline {1.3.2}Análise de Convergência}{9}{subsection.1.3.2}%
\contentsline {section}{\numberline {1.4}Regra da Cadeia Vetorial e Jacobianos}{10}{section.1.4}%
\contentsline {subsection}{\numberline {1.4.1}Diferença entre Gradiente e Jacobiano}{10}{subsection.1.4.1}%
\contentsline {chapter}{\numberline {2}Implementação Base em C: Estruturas e Gerenciamento de Memória}{11}{chapter.2}%
\contentsline {section}{\numberline {2.1}Gerenciamento de Memória para Tensores}{11}{section.2.1}%
\contentsline {section}{\numberline {2.2}Funções de Criação e Destruição}{12}{section.2.2}%
\contentsline {section}{\numberline {2.3}Operações Básicas Otimizadas}{13}{section.2.3}%
\contentsline {section}{\numberline {2.4}Produto Matricial Otimizado}{13}{section.2.4}%
\contentsline {section}{\numberline {2.5}Estratégias de Otimização de Memória}{14}{section.2.5}%
\contentsline {subsection}{\numberline {2.5.1}Pooling de Alocação}{14}{subsection.2.5.1}%
\contentsline {chapter}{\numberline {3}Rede Neural: Matemática e Implementação Detalhada}{15}{chapter.3}%
\contentsline {section}{\numberline {3.1}Arquitetura de uma Rede Neural}{15}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1}Neurônio Artificial: Modelo Matemático}{15}{subsection.3.1.1}%
\contentsline {section}{\numberline {3.2}Backpropagation: Derivação Passo a Passo}{16}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Caso Simples: 2 Camadas}{16}{subsection.3.2.1}%
\contentsline {subsubsection}{Derivadas da Camada de Saída}{16}{section*.3}%
\contentsline {subsubsection}{Derivadas da Camada Oculta}{16}{section*.4}%
\contentsline {subsection}{\numberline {3.2.2}Implementação Completa do Backprop}{17}{subsection.3.2.2}%
\contentsline {section}{\numberline {3.3}Inicialização de Pesos}{18}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}Xavier/Glorot Initialization}{18}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}He Initialization}{18}{subsection.3.3.2}%
\contentsline {chapter}{\numberline {4}Sistema de Autograd Completo}{21}{chapter.4}%
\contentsline {section}{\numberline {4.1}Arquitetura do Grafo Computacional}{21}{section.4.1}%
\contentsline {section}{\numberline {4.2}Implementação de Operações com Grafo}{22}{section.4.2}%
\contentsline {section}{\numberline {4.3}Topological Sort e Propagação Reversa}{23}{section.4.3}%
\contentsline {chapter}{\numberline {5}Camadas Avançadas e Funções de Ativação}{25}{chapter.5}%
\contentsline {section}{\numberline {5.1}Camada Linear (Fully Connected)}{25}{section.5.1}%
\contentsline {section}{\numberline {5.2}Funções de Ativação com Autograd}{27}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1}ReLU e Leaky ReLU}{27}{subsection.5.2.1}%
\contentsline {subsection}{\numberline {5.2.2}Softmax Estável Numericamente}{28}{subsection.5.2.2}%
\contentsline {chapter}{\numberline {6}Redes Convolucionais: Implementação Profunda}{31}{chapter.6}%
\contentsline {section}{\numberline {6.1}Fundamentos da Convolução Discreta}{31}{section.6.1}%
\contentsline {subsection}{\numberline {6.1.1}Implementação Ingênua vs Otimizada}{31}{subsection.6.1.1}%
\contentsline {section}{\numberline {6.2}Backpropagation em Convolução}{33}{section.6.2}%
\contentsline {section}{\numberline {6.3}Otimizações: Im2Col e GEMM}{35}{section.6.3}%
\contentsline {chapter}{\numberline {7}Otimizadores: Teoria e Implementação}{39}{chapter.7}%
\contentsline {section}{\numberline {7.1}Stochastic Gradient Descent (SGD)}{39}{section.7.1}%
\contentsline {subsection}{\numberline {7.1.1}Com e sem Momentum}{39}{subsection.7.1.1}%
\contentsline {section}{\numberline {7.2}Adam: Adaptive Moment Estimation}{41}{section.7.2}%
\contentsline {chapter}{\numberline {8}Treinamento e Validação}{43}{chapter.8}%
\contentsline {section}{\numberline {8.1}DataLoader e Batching}{43}{section.8.1}%
\contentsline {section}{\numberline {8.2}Loop de Treinamento Completo}{45}{section.8.2}%
\contentsline {chapter}{\numberline {9}Serialização e Persistência de Modelos}{47}{chapter.9}%
\contentsline {section}{\numberline {9.1}Salvando e Carregando Modelos}{47}{section.9.1}%
\contentsline {chapter}{\numberline {10}Estudos de Caso e Projetos Práticos}{51}{chapter.10}%
\contentsline {section}{\numberline {10.1}Exemplo 1: MNIST do Zero}{51}{section.10.1}%
\contentsline {section}{\numberline {10.2}Exemplo 2: CNN para CIFAR-10}{52}{section.10.2}%
\contentsline {chapter}{\numberline {11}Otimizações Avançadas e Performance}{55}{chapter.11}%
\contentsline {section}{\numberline {11.1}BLAS-Level Optimizations}{55}{section.11.1}%
\contentsline {subsection}{\numberline {11.1.1}Tiling para Cache L1/L2}{55}{subsection.11.1.1}%
\contentsline {subsection}{\numberline {11.1.2}SIMD Intrinsics}{56}{subsection.11.1.2}%
\contentsline {section}{\numberline {11.2}Parallelism with OpenMP}{57}{section.11.2}%
\contentsline {chapter}{\numberline {12}Próximos Passos: Além do Framework}{59}{chapter.12}%
\contentsline {section}{\numberline {12.1}Suporte a GPU com CUDA}{59}{section.12.1}%
\contentsline {section}{\numberline {12.2}Implementação de Transformers}{60}{section.12.2}%
\contentsline {section}{\numberline {12.3}Mixed Precision Training}{60}{section.12.3}%
